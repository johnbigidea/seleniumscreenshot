{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as requests\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import random\n",
    "\n",
    "r =  range(1,10000)\n",
    "bloglist=[]\n",
    "n=0\n",
    "headers = {'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'}\n",
    "\n",
    "for a in r:\n",
    "    url = 'https://www.indeed.com/jobs?q=data+analyst+intern&start=' + str(a*10)\n",
    "\n",
    "    req =  requests.Request(url,\n",
    "                            data=None,\n",
    "                            headers=headers)\n",
    "    \n",
    "    \n",
    "    html = urlopen(url).read().decode('utf-8')\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(html,features='lxml')\n",
    "    sub_links = soup.find_all('a', {'href': re.compile('/i/.*?\\.html')})\n",
    "    for sub in sub_links:\n",
    "        if sub['href'] in bloglist:\n",
    "            continue\n",
    "        else:\n",
    "            bloglist.append(sub['href'])\n",
    "\n",
    "for d in bloglist:\n",
    "    url2= 'http://www.mafengwo.cn'+str(d)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        html2 = urlopen(url2).read().decode('utf-8')\n",
    "        soup2 = BeautifulSoup(html2,features='lxml')\n",
    "        img_links = soup2.find_all('img', {'data-src': re.compile('.*?\\.jpeg')})\n",
    "        name = soup2.find('meta',{'name':'author'})\n",
    "        strname = str(name)\n",
    "        match = re.search(r\"(\\d+),(.+)\\\" name\",strname)\n",
    "        print(match.group(2))\n",
    "        file_a_n = match.group(2)\n",
    "        \n",
    "        try:\n",
    "            people = soup2.find('li',{'class': 'people'})\n",
    "            print(people)\n",
    "            strpeople = str(people)\n",
    "            speople = strpeople.split('</span>')[1].strip('</li>')\n",
    "            print(speople)\n",
    "        except:\n",
    "            speople = 'none'\n",
    "            \n",
    "        try:\n",
    "\n",
    "            time = soup2.find('li',{'class': 'time'})\n",
    "            strtime = str(time)\n",
    "            match2 = re.search(r\"(\\d+-\\d+-\\d+)\",strtime)\n",
    "            sdate = match2.group()\n",
    "            print(sdate)\n",
    "        except:\n",
    "            sdate = 'none'\n",
    "        try:\n",
    "#             html2 = urlopen(url2).read().decode('utf-8')\n",
    "#             soup2 = BeautifulSoup(html2,features='lxml')\n",
    "            day = soup2.find('li',{'class': 'day'})\n",
    "            print(day)\n",
    "            strday = str(day)\n",
    "            match3 = re.search(r\"(\\d+)\",strday)\n",
    "            sday = match3.group()\n",
    "            print(sday)\n",
    "        except:\n",
    "            sday = 'none'\n",
    "        try:\n",
    "#             html2 = urlopen(url2).read().decode('utf-8')\n",
    "#             soup2 = BeautifulSoup(html2,features='lxml')\n",
    "            cost = soup2.find('li',{'class': 'cost'})\n",
    "            print(cost)\n",
    "            strcost = str(cost)\n",
    "            match4 = re.search(r\"(\\d+)\",strcost)\n",
    "            scost = match4.group()\n",
    "            print(scost)\n",
    "        except:\n",
    "            scost = 'none'\n",
    "\n",
    "            \n",
    "        for link in img_links:\n",
    "            \n",
    "            print(link['data-src'])\n",
    "            content= urlopen(link['data-src']).read()\n",
    "            with open(str(n)+'_'+file_a_n+'_'+sdate+'_'+sday+'_'+scost+'.jpeg','wb') as f:\n",
    "                f.write(content)\n",
    "                n+=1\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
